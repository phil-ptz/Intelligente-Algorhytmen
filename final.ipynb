{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ddd8818",
   "metadata": {},
   "source": [
    "# Programmentwurf zu Aufgabe 1: Aussagenlogische Formel in Disjunkter Normalform als zweischichtiges Neuronales Netz\n",
    "\n",
    "Autoren: Felix Luck, Jannes Süß, Julian Blönnigen, Phil Potratz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5879dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fa52f1",
   "metadata": {},
   "source": [
    "## Aufgabe (a) und (b): Implementierung des Netzes inklusive Dokumentation\n",
    "\n",
    "In diesem Teil ist das wurde das neuronale Netz innerhalb von der Funktion training() implementiert. Hier gibt es außerdem die Aktivierungsfunktion sgn() und die Funktion create_data(), welche eine zufällige Formel in DNF erstellt inklusive zufälliger Belegungen. Wir haben zuletzt noch die Funktion summary() hinzugefügt, um ausgewählte Daten anschaulich darzustellen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02e3255",
   "metadata": {},
   "source": [
    "### Erstellung der Trainingsdaten\n",
    "Hier werden die Trainingsdaten erstellt.\n",
    "\n",
    "Am Anfang wird ein zweidimensionales Array mit zufälligen Belegungungen für die Variablen erstellt. Dieses Array hat die Größe n (Anzahl der Variablen) mal daten_umgfang (Anzahl der unterschiedlichen Belegungen).\n",
    "\n",
    "Danach wird die Aussagenlogische Formel erstellt, welche aus einer Liste der Monome besteht. Die Monome bestehen wiederum aus den Indizies der Variablen. Wenn ein Index negativ ist bedeutet dies, dass dieses Literal negiert ist, hier wird dann als Index der Betrag des negativen Indexes genommen.\n",
    "\n",
    "Zum Schluss werden die Wahrheitswerte der einzelnen Belegungen nochn generiert. Dafür wird eine Funktion genommen, welche jedes Monom auf den Wahrheitswert prüft. Wenn ein Monom wahr ist wird 1 zurückgegeben (Belegung ist wahr), sonst wird -1 zurückgegeben (Belegung ist falsch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c94f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(n, m, l, daten_umfang):\n",
    "    # Erstellung von zufälligen Belegungen der Eingangsvariablen\n",
    "    x_array = np.random.choice([-1, 1], size=(daten_umfang, n))\n",
    "\n",
    "    # Erstellung der Aussagenlogischen Formel in DNF-Form\n",
    "    monome = []\n",
    "    for _ in range(m):\n",
    "        monom = []\n",
    "        \n",
    "        # Zufällige, eindeutige Auswahl von Variablenindizes\n",
    "        variablen = np.random.choice(n, size=l, replace=False)\n",
    "        \n",
    "        for v in variablen:\n",
    "            # Zufällig entscheiden, ob normal oder negiert\n",
    "            if np.random.rand() < 0.5:\n",
    "                monom.append(v+1)   # Normal\n",
    "            else:\n",
    "                monom.append((v+1)*(-1))  # Negiert\n",
    "        \n",
    "        monome.append(monom)\n",
    "\n",
    "    # Wahrheitswert der Aussagenlogischen Formel zurückgeben\n",
    "    def aussagenlogische_formel(x):\n",
    "        for monom in monome:\n",
    "            alle_bedingungen_erfüllt = True\n",
    "            \n",
    "            for i in monom:\n",
    "                index = abs(i)\n",
    "\n",
    "                # Positive Variable (nicht negiert)\n",
    "                if i >= 0:\n",
    "                    if x[index-1] != 1:\n",
    "                        alle_bedingungen_erfüllt = False\n",
    "                        break\n",
    "                # Negative Variable (negiert)\n",
    "                else:\n",
    "                    if x[index-1] != -1:\n",
    "                        alle_bedingungen_erfüllt = False\n",
    "                        break\n",
    "            \n",
    "            # Alle Variablen eines Monoms sind wahr\n",
    "            if alle_bedingungen_erfüllt:\n",
    "                return 1\n",
    "\n",
    "        return -1  # Kein Monom erfüllt\n",
    "\n",
    "    # Zielausgaben generieren\n",
    "    p_array = np.array([aussagenlogische_formel(x) for x in x_array])\n",
    "\n",
    "    return x_array, p_array, monome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f629040c",
   "metadata": {},
   "source": [
    "## Aktivierungsfunktion\n",
    "Als Aktivierungsfunktion wird die sgn()-Funktion genutzt, welche bei Werten größer und gleich null eins zurückgibt und sonst minus eins:\n",
    "\n",
    "$\n",
    "\\operatorname{sgn}(x) = \\begin{cases} \n",
    "1, & \\text{falls } x \\geq 0 \\\\\n",
    "-1, & \\text{falls } x < 0\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aed8850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgn(x):\n",
    "    return np.where(x >= 0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3044dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "def training(x_array, p_array, daten_umfang, epochs, eta, w, W, v, V):\n",
    "    print(\"\\n===== Training =====\")\n",
    "    for epoch in range(epochs):\n",
    "        correct_predictions = 0\n",
    "        sum_fehler = 0\n",
    "        \n",
    "        for x, p in zip(x_array, p_array):\n",
    "            \n",
    "            # Vorwärtspass\n",
    "            z = sgn(np.dot(w, x) - v)\n",
    "            y = sgn(np.dot(W, z) - V)\n",
    "\n",
    "            # Fehler\n",
    "            fehler = p - y\n",
    "            sum_fehler += abs(fehler)\n",
    "\n",
    "            # Gewichts-Updates (Fehler-Rückübertragung)\n",
    "            delta_W = eta * fehler * z\n",
    "            delta_w = eta * np.outer(W.flatten() * fehler, x)\n",
    "            \n",
    "            delta_V = -eta * fehler\n",
    "            delta_v = -eta * fehler * W.flatten()\n",
    "\n",
    "            # Aktualisierung\n",
    "            w += delta_w\n",
    "            W += delta_W\n",
    "            v += delta_v\n",
    "            V += delta_V\n",
    "\n",
    "            if y == p:\n",
    "                correct_predictions += 1\n",
    "        \n",
    "        # Ausgabe alle 1000 Epochen\n",
    "        if epoch % (epochs // 10) == 0 or epoch == epochs - 1:\n",
    "            acc = correct_predictions / daten_umfang\n",
    "            print(f\"Epoche {epoch+1}: Ergebnis: {correct_predictions}/{daten_umfang} ({acc:.2%}) Fehler: {sum_fehler}\")\n",
    "\n",
    "    print(\"Training abgeschlossen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea83996d",
   "metadata": {},
   "source": [
    "Hier wird eine Zusammenfassung der gewählten Konstanten und der Zufällig generierten Formel und deren Belegungen ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3395c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(n,m,l,daten_umfang, eta,epochs,x_array,p_array,monome):\n",
    "    # Kleine Zusammenfassung\n",
    "\n",
    "    # Konstannten\n",
    "    print(\"===== Einstellungen =====\")\n",
    "    print(f\"Anzahl Eingangsvariablen (n): {n}\")\n",
    "    print(f\"Anzahl Monome (m): {m}\")\n",
    "    print(f\"Anzahl Literale pro Monom (l): {l}\")\n",
    "    print(f\"Anzahl Trainingsdaten: {daten_umfang}\")\n",
    "    print(f\"Lernrate (eta): {eta}\")\n",
    "    print(f\"Anzahl Epochen: {epochs}\")\n",
    "\n",
    "    # Aussagenlogische Formel\n",
    "    print(\"\\n===== Generierte DNF-Formel =====\")\n",
    "    dnf_teile = []\n",
    "    for monom in monome:\n",
    "        bedingungen = []\n",
    "        for var in monom:\n",
    "            if var >= 0:\n",
    "                bedingungen.append(f\"x{var}\")\n",
    "            else:\n",
    "                bedingungen.append(f\"¬x{abs(var)}\")\n",
    "        dnf_teile.append(\"(\" + \" ∧ \".join(bedingungen) + \")\")\n",
    "\n",
    "    dnf_formel = \" ∨ \".join(dnf_teile)\n",
    "    print(dnf_formel)\n",
    "\n",
    "    # Teil der Belegungen\n",
    "    print(\"\\n===== Belegungen =====\")\n",
    "    for i in range(min(5, len(x_array))):\n",
    "        print(f\"[{i}]: {x_array[i]}  -->  [{p_array[i]}]\")\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15068272",
   "metadata": {},
   "source": [
    "## Aufgabe (c): Testen mit perfekten Gewichten und Schwellenwerten\n",
    "\n",
    "Hier erstellen wir mithilfe der Funktion create_gewichte_und_schwellen() die Gewichte und Schwellenwerte, wie in den Anforderungen beschrieben, damit die DNF sofort implementiert wird. Danach wird trainiert und geschaut, ob sich die Gewichte und Schwellenwerte noch ändern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b4b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung von theoretisch perfekten Gewichten und Schwellenwerten\n",
    "def create_gewichte_und_schwellen(monome, n):\n",
    "    \"\"\"\n",
    "    monome: Liste von Listen mit Literalen (positiv für x_i, negativ für ¬x_i)\n",
    "    n: Gesamtanzahl der Variablen\n",
    "    \n",
    "    Rückgabe:\n",
    "    - w: (m, n) Gewichtsmatrix für die Zwischenschicht\n",
    "    - v: (m,) Schwellenwerte für die Zwischenschicht\n",
    "    - W: (1, m) Gewichtsmatrix für die Ausgabeschicht\n",
    "    - V: (1,) Schwellenwert für die Ausgabeschicht\n",
    "    \"\"\"\n",
    "    m = len(monome)  # Anzahl der Monome\n",
    "    \n",
    "    w = np.zeros((m, n))\n",
    "    v = np.zeros(m)\n",
    "    \n",
    "    for i, monom in enumerate(monome):\n",
    "        for j, literal in enumerate(monom):\n",
    "            if literal >= 0:\n",
    "                w[i, literal-1] = 1.0\n",
    "            else:\n",
    "                w[i, abs(literal)-1] = -1.0\n",
    "        v[i] = len(monom)  # Schwellenwert = Anzahl Literale im Monom\n",
    "    \n",
    "    W = np.ones((1, m))\n",
    "    V = np.array([1 - m], dtype=float)  # Schwellenwert für die Ausgabeschicht\n",
    "    \n",
    "    return w, v, W, V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5691d37d",
   "metadata": {},
   "source": [
    "Die Ausgabe zeigt, dass es keinen Fehler gibt (p = y). Daher funktioniert die Implementierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Konstanten ###\n",
    "\n",
    "# Anzahl Eingangsvariablen\n",
    "n = 10\n",
    "\n",
    "# Anzahl Monome\n",
    "m = 5\n",
    "\n",
    "# Anzahl Literale pro Monom\n",
    "l = 10\n",
    "\n",
    "# Anzahl Trainingsdaten\n",
    "daten_umfang = 1000\n",
    "\n",
    "# Lernrate\n",
    "eta = 0.05\n",
    "\n",
    "# Anzahl Epochen\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "\n",
    "### Daten generieren und Training starten ###\n",
    "\n",
    "# Trainingsdaten generieren\n",
    "x_array, p_array, monome = create_data(n, m, l, daten_umfang)\n",
    "\n",
    "# Zusammenfassung der Daten\n",
    "summary(n, m, l, daten_umfang, eta, epochs, x_array, p_array, monome)\n",
    "\n",
    "# Perfekte Gewichte und Schwellenwerte erstellen\n",
    "w, v, W, V = create_gewichte_und_schwellen(monome, n)\n",
    "\n",
    "# Training starten\n",
    "training(x_array, p_array, daten_umfang, epochs, eta, w, W, v, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cbfd2d",
   "metadata": {},
   "source": [
    "## Aufgabe (d): Testen von anderen Gewichten und Schwellenwerten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b06ba5",
   "metadata": {},
   "source": [
    "### Test mit leicht veränderten Gewichten und Schwellenwerten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d044472",
   "metadata": {},
   "source": [
    "Am Anfang gibt es noch Fehler, dieser wird dann aber korrigiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8880a83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gewichte und Schwellenwerte leicht ändern\n",
    "\n",
    "noise = 1\n",
    "w_noise = w + np.random.uniform(-noise, noise, size=w.shape)\n",
    "v_noise = v + np.random.uniform(-noise, noise, size=v.shape)\n",
    "W_noise = W + np.random.uniform(-noise, noise, size=W.shape)\n",
    "V_noise = V + np.random.uniform(-noise, noise, size=V.shape)\n",
    "\n",
    "# Testen der Gewichte\n",
    "training(x_array, p_array, daten_umfang, epochs, eta, w_noise, W_noise, v_noise, V_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb283aa",
   "metadata": {},
   "source": [
    "Zwar gibt es auch keine Fehler mehr, aber trotzdem sind die Gewichte und Schwellwerte nicht gleich zu denen, die theoretisch ermittelt wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002893f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich der Gewichte und Schwellenwerte\n",
    "print(f\"w = w_noise: {np.array_equal(w, w_noise)}\")\n",
    "print(f\"v = v_noise: {np.array_equal(v, v_noise)}\")\n",
    "print(f\"W = W_noise: {np.array_equal(W, W_noise)}\")\n",
    "print(f\"V = V_noise: {np.array_equal(V, V_noise)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011f31fb",
   "metadata": {},
   "source": [
    "### Test mit zufälligen Gewichten und Schwellenwerten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba72fd01",
   "metadata": {},
   "source": [
    "Das Ergebnis ist nie ganz perfekt. Die Accuracy nähert sich den 100% an, erreicht sie aber nie. Das liegt daran, dass die Fehlerrückübertragung in einem lokalen Minima liegt. Hier wird also gezeigt, das es für den Algorithmus schwieriger ist blind die DNF zu erlernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f907e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zufällige Gewichte initialisieren\n",
    "\n",
    "# Zufallsfakktor (Damit Werte nicht zu weit zerstreut sind)\n",
    "zf = 0.1\n",
    "\n",
    "w_random = np.random.randn(m, n) * zf\n",
    "W_random = np.random.randn(1, m) * zf\n",
    "\n",
    "v_random = np.random.randn(m) * zf\n",
    "V_random = np.random.randn(1) * zf\n",
    "\n",
    "# Testen der Gewichte\n",
    "training(x_array, p_array, daten_umfang, epochs, eta, w_random, W_random, v_random, V_random)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
